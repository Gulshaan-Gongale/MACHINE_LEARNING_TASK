{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38cae31b",
   "metadata": {},
   "source": [
    "- TEXT PTREPROCESSING = \"Text preprocessing involves transforming text into a clean and consistent format that can then be fed into a model for further analysis and learning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08330012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8b1f65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = '''Betty Botter bought some butter\n",
    "But she said the butter’s bitter\n",
    "If I put it in my batter, it will make my batter bitter\n",
    "But a bit of better butter will make my batter better\n",
    "So ‘twas better Betty Botter bought a bit of better butter'''\n",
    "''''''\n",
    "doc2= '''Susie works in a shoeshine shop. Where she shines she sits, and where she sits she shines.'''\n",
    "\n",
    "doc3 = '''I have got a date at a quarter to eight; I’ll see you at the gate, so don’t be late.'''\n",
    "doc4 = '''You know New York, you need New York, you know you need unique New York.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bcbce8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdata = pd.DataFrame({\"docs\" : [doc1, doc2, doc3, doc4]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "024a9a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Betty Botter bought some butter\\nBut she said ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Susie works in a shoeshine shop. Where she shi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have got a date at a quarter to eight; I’ll ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You know New York, you need New York, you know...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                docs\n",
       "0  Betty Botter bought some butter\\nBut she said ...\n",
       "1  Susie works in a shoeshine shop. Where she shi...\n",
       "2  I have got a date at a quarter to eight; I’ll ...\n",
       "3  You know New York, you need New York, you know..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb15ebbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Betty Botter bought some butter\\nBut she said ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Susie works in a shoeshine shop. Where she shi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have got a date at a quarter to eight; I’ll ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You know New York, you need New York, you know...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                docs\n",
       "0  Betty Botter bought some butter\\nBut she said ...\n",
       "1  Susie works in a shoeshine shop. Where she shi...\n",
       "2  I have got a date at a quarter to eight; I’ll ...\n",
       "3  You know New York, you need New York, you know..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdata.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05c21fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    betty botter bought some butter\\nbut she said ...\n",
       "1    susie works in a shoeshine shop. where she shi...\n",
       "2    i have got a date at a quarter to eight; i’ll ...\n",
       "3    you know new york, you need new york, you know...\n",
       "Name: docs, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdata[\"docs\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e64733e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    BETTY BOTTER BOUGHT SOME BUTTER\\nBUT SHE SAID ...\n",
       "1    SUSIE WORKS IN A SHOESHINE SHOP. WHERE SHE SHI...\n",
       "2    I HAVE GOT A DATE AT A QUARTER TO EIGHT; I’LL ...\n",
       "3    YOU KNOW NEW YORK, YOU NEED NEW YORK, YOU KNOW...\n",
       "Name: docs, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdata[\"docs\"].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "631ebcb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    betty botter bought some butter\\nbut she said ...\n",
       "1    susie works in a shoeshine shop. where she shi...\n",
       "2    i have got a date at a quarter to eight; i’ll ...\n",
       "3    you know new york, you need new york, you know...\n",
       "Name: docs, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdata[\"docs\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6905b70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Betty Botter Bought Some Butter\\nBut She Said ...\n",
       "1    Susie Works In A Shoeshine Shop. Where She Shi...\n",
       "2    I Have Got A Date At A Quarter To Eight; I’Ll ...\n",
       "3    You Know New York, You Need New York, You Know...\n",
       "Name: docs, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdata[\"docs\"].str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "953b4a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Betty botter bought some butter\\nbut she said ...\n",
       "1    Susie works in a shoeshine shop. where she shi...\n",
       "2    I have got a date at a quarter to eight; i’ll ...\n",
       "3    You know new york, you need new york, you know...\n",
       "Name: docs, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdata[\"docs\"].str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80b5e835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you know new york, you need new york, you know you need unique new york.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdata[\"docs\"][3].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02f15f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I HAVE GOT A DATE AT A QUARTER TO EIGHT; I’LL SEE YOU AT THE GATE, SO DON’T BE LATE.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdata[\"docs\"][2].upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483db63f",
   "metadata": {},
   "source": [
    "## CONVERTING TO UNIFORM CASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8136c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upperconversion_case(x):\n",
    "    return x.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d85a173",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdata[\"docs\"]= upperconversion_case(dfdata[\"docs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1eb43ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BETTY BOTTER BOUGHT SOME BUTTER\\nBUT SHE SAID ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUSIE WORKS IN A SHOESHINE SHOP. WHERE SHE SHI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I HAVE GOT A DATE AT A QUARTER TO EIGHT; I’LL ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YOU KNOW NEW YORK, YOU NEED NEW YORK, YOU KNOW...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                docs\n",
       "0  BETTY BOTTER BOUGHT SOME BUTTER\\nBUT SHE SAID ...\n",
       "1  SUSIE WORKS IN A SHOESHINE SHOP. WHERE SHE SHI...\n",
       "2  I HAVE GOT A DATE AT A QUARTER TO EIGHT; I’LL ...\n",
       "3  YOU KNOW NEW YORK, YOU NEED NEW YORK, YOU KNOW..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cbc0325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowerconversion_case(x):\n",
    "    return x.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0406deef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdata[\"docs\"]= lowerconversion_case(dfdata[\"docs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d6f2de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>betty botter bought some butter\\nbut she said ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>susie works in a shoeshine shop. where she shi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i have got a date at a quarter to eight; i’ll ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you know new york, you need new york, you know...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                docs\n",
       "0  betty botter bought some butter\\nbut she said ...\n",
       "1  susie works in a shoeshine shop. where she shi...\n",
       "2  i have got a date at a quarter to eight; i’ll ...\n",
       "3  you know new york, you need new york, you know..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e04aa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def titleconversion_case(x):\n",
    "    return x.str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c886857",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdata[\"docs\"] = titleconversion_case(dfdata[\"docs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d022027b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Betty Botter Bought Some Butter\\nBut She Said ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Susie Works In A Shoeshine Shop. Where She Shi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I Have Got A Date At A Quarter To Eight; I’Ll ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You Know New York, You Need New York, You Know...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                docs\n",
       "0  Betty Botter Bought Some Butter\\nBut She Said ...\n",
       "1  Susie Works In A Shoeshine Shop. Where She Shi...\n",
       "2  I Have Got A Date At A Quarter To Eight; I’Ll ...\n",
       "3  You Know New York, You Need New York, You Know..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38689231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capitalizeconversion_case(x):\n",
    "    return x.str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5e819a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdata[\"docs\"]= capitalizeconversion_case(dfdata[\"docs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44d2c4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Betty botter bought some butter\\nbut she said ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Susie works in a shoeshine shop. where she shi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have got a date at a quarter to eight; i’ll ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You know new york, you need new york, you know...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                docs\n",
       "0  Betty botter bought some butter\\nbut she said ...\n",
       "1  Susie works in a shoeshine shop. where she shi...\n",
       "2  I have got a date at a quarter to eight; i’ll ...\n",
       "3  You know new york, you need new york, you know..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cf5f43",
   "metadata": {},
   "source": [
    "## HANDLING HTML TAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "edd08806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41a11d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"<b>HELLO WORLD</b>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65949f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' HELLO WORLD '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"<.*?>\", \" \", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b30ae4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = \"<b>WELCOME TO DATA SCIENCE REALM</b>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a5b0b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' WELCOME TO DATA SCIENCE REALM '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"<.*?>\", \" \", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42cc25f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags(x):\n",
    "    return re.sub(r\"<.*?>\", \" \", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc7e41c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdata[\"docs\"] = dfdata[\"docs\"].apply(remove_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a682b58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Betty botter bought some butter\\nbut she said ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Susie works in a shoeshine shop. where she shi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have got a date at a quarter to eight; i’ll ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You know new york, you need new york, you know...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                docs\n",
       "0  Betty botter bought some butter\\nbut she said ...\n",
       "1  Susie works in a shoeshine shop. where she shi...\n",
       "2  I have got a date at a quarter to eight; i’ll ...\n",
       "3  You know new york, you need new york, you know..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a147588",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = \"Learn data science course well . http://wwww.usedu.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ba99b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have got'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdata[\"docs\"][2][0:10:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e73f68b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ou know new york, you ne'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdata[\"docs\"][3][1:25:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a93bc61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Betty botter bought some butter\\nbut she said ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Susie works in a shoeshine shop. where she shi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have got a date at a quarter to eight; i’ll ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You know new york, you need new york, you know...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                docs\n",
       "0  Betty botter bought some butter\\nbut she said ...\n",
       "1  Susie works in a shoeshine shop. where she shi...\n",
       "2  I have got a date at a quarter to eight; i’ll ...\n",
       "3  You know new york, you need new york, you know..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b22f070c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Betty botter bought some butter\\nbut she said the butter’s bitter\\nif i put it in my batter, it will make my batter bitter\\nbut a bit of better butter will make my batter better\\nso ‘twas better betty botter bought a bit of better butter'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdata[\"docs\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "864138a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handlingnewline_char(x):\n",
    "    return re.sub(r'\\n', \" \",x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "139394b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdata[\"docs\"] = dfdata[\"docs\"].apply(handlingnewline_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "11044140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Betty botter bought some butter but she said the butter’s bitter if i put it in my batter, it will make my batter bitter but a bit of better butter will make my batter better so ‘twas better betty botter bought a bit of better butter'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdata[\"docs\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f0c03a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handlingnewline_char(x):\n",
    "    return re.sub(r'\\n', ' ', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c7a94d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdata[\"docs\"] = dfdata[\"docs\"].apply(handlingnewline_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d0771806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Betty botter bought some butter but she said the butter’s bitter if i put it in my batter, it will make my batter bitter but a bit of better butter will make my batter better so ‘twas better betty botter bought a bit of better butter'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdata[\"docs\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a416faa",
   "metadata": {},
   "source": [
    "## HANDLING SPECIAL CHARACTER AND NUMBERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b139dcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "U = \"9372@HEY BUDDY_**9.77ILU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "39c01b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9372@HEY BUDDY_**9.77ILU'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'^[a-zA-z]', ' ', U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "35a6b362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 372@HEY BUDDY_**9.77ILU'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'^[a-zA-Z0-9]', ' ', U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b8c9e8ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' @  BUDDY_** . '"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"\\b[a-zA-Z-0-9]+\\b\",\" \", U)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8ad142f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9372@  BUDDY_**9.77ILU'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"\\b[a-zA-Z]+\\b\",\" \", U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ee42899c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@', ' ', '**', '.']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\W+', U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f1867b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9372 HEY BUDDY_  9.77ILU'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'[@**?]',' ', U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c070d0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['**9', '.77']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\W+\\d+', U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ec5916db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9372 HEY BUDDY   9.77ILU'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'[@_**?]',' ', U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "586b6d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9372 HEY BUDDY   9 77ILU'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'[@_**\\.?]',' ', U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "31e1c311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'     HEY BUDDY       ILU'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'[@_**\\d+\\.?]',' ', U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fe6357b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9372', '9', '77']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\d+', U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5b2d6631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2@HEY BUDDY_']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"\\d@\\w+\\s\\w+\",U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ab082c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HEY BUDDY_']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\b[^@_?]\\w+\\s\\w+', U)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56c0929",
   "metadata": {},
   "source": [
    "## REMOVING URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2d594cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"check out this american univeristy link https://www.princeton.edu/admission-aid/international-students\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f91b17bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"check out this american univeristy link  https://www.princeton.edu/admission-aid/international-students\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eae19ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    pattern = re.compile(r'https?://S+|www\\.\\S+')\n",
    "    return pattern.sub(r'' , text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5b1205c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'check out this american univeristy link https://'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_url(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2df80a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    pattern = re.compile(r'\\b(https?://)\\S+|www\\.\\S+\\w')\n",
    "    return pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c40beb78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'check out this american univeristy link  '"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_url(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6b8d2601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'check out this american univeristy link '"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_url(text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1132ac46",
   "metadata": {},
   "source": [
    "## CHAT WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1b2ad79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_words = {\n",
    "    \"AFAIK\" : \"AS FAR AS I KNOW\",\n",
    "    \"ASAP\": \"AS SSON AS POSSIBLE\",\n",
    "    \"ATK\" : \"AT THE KEYBOARD\",\n",
    "    \"ATM\" : \"AT THE MOMENT\",\n",
    "    \"BAK\": \"BACK AT KEYBOARD\",\n",
    "    \"BBL\" :\"BE BACK LATER\",\n",
    "    \"BRT\" : \"BE RIGHT THERE\",\n",
    "    \"BRB\" : \"BE RIGHT BACK\",\n",
    "    \"BFN\" : \"BYE FOR NOW\",\n",
    "    \"BBS\" : \"BE BACK SOON\",\n",
    "    \"TTYL\" : \"TALK TO YOU LATER\",\n",
    "    \"BTW\" : \"BY THE WAY\", \n",
    "    \"SUL\" : \"SEE YOU LATER\",\n",
    "    \"FAQ\" : \"FREQUNTLY ASKED QUENTIONS\",\n",
    "    \"FYI\": \"FOR YOUR INFORMATION\",\n",
    "    \"GAL\": \"GET A LIFE\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "690d42e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AFAIK': 'AS FAR AS I KNOW',\n",
       " 'ASAP': 'AS SSON AS POSSIBLE',\n",
       " 'ATK': 'AT THE KEYBOARD',\n",
       " 'ATM': 'AT THE MOMENT',\n",
       " 'BAK': 'BACK AT KEYBOARD',\n",
       " 'BBL': 'BE BACK LATER',\n",
       " 'BRT': 'BE RIGHT THERE',\n",
       " 'BRB': 'BE RIGHT BACK',\n",
       " 'BFN': 'BYE FOR NOW',\n",
       " 'BBS': 'BE BACK SOON',\n",
       " 'TTYL': 'TALK TO YOU LATER',\n",
       " 'BTW': 'BY THE WAY',\n",
       " 'SUL': 'SEE YOU LATER',\n",
       " 'FAQ': 'FREQUNTLY ASKED QUENTIONS',\n",
       " 'FYI': 'FOR YOUR INFORMATION',\n",
       " 'GAL': 'GET A LIFE'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e5a705df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_conversation(text):\n",
    "    new_text = []\n",
    "    for w in text.split():\n",
    "        if w.upper() in chat_words:\n",
    "            new_text.append(chat_words[w.upper()])\n",
    "        else:\n",
    "            new_text.append(w)\n",
    "            \n",
    "    return \" \".join(new_text)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "04522d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FOR YOUR INFORMATION NEW YORK IS THE BEST CITY IN THE WORLD'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_conversation(\"FYI NEW YORK IS THE BEST CITY IN THE WORLD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1fa0fac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"BYE FOR NOW I'LL TALK TO YOU TOMORROW\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_conversation(\"BFN I'LL TALK TO YOU TOMORROW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a6f17ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_conversion(text):\n",
    "    New_text = []\n",
    "    for i in text.split():\n",
    "        if i.upper() in chat_words:\n",
    "            New_text.append(chat_words[i.upper()])\n",
    "        else:\n",
    "            New_text.append(i)\n",
    "\n",
    "    return \" \".join(New_text)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9d261516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"wait for me i'll BE BACK SOON\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_conversion(\"wait for me i'll BBS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6ba449aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TALK TO YOU LATER'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_conversion(\"TTYL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bbdcace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdata[\"docs\"] = dfdata[\"docs\"].apply(chat_conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3577dea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have got a date at a quarter to eight; i’ll see you at the gate, so don’t be late.'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdata[\"docs\"][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f16df5",
   "metadata": {},
   "source": [
    "## TOKENIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5bd436e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOKENIZATION IS THE PROCESS OF BREAKING OF TEXT INTO SMALLER PARTS, SMALLER PARTS MIGHT BE WORDS, SENTENCES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2a22e9",
   "metadata": {},
   "source": [
    "- USING SPLIT FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "331d94ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"I AM GOING TO AMERICA FOR JOB AND MASTER'S\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "1f5f0aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'AM', 'GOING', 'TO', 'AMERICA', 'FOR', 'JOB', 'AND', \"MASTER'S\"]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d770a5f",
   "metadata": {},
   "source": [
    "- SENTENCE TOKENIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "00860779",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent2 = \"I AM GOING TO AMERICA FOR JOB AND MASTER'S. I WILL BE THERE FOR 5 YEARS. LETS\\'S HOPE THE TRIP TO BE GREAT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9bce28ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I AM GOING TO AMERICA FOR JOB AND MASTER'S\",\n",
       " ' I WILL BE THERE FOR 5 YEARS',\n",
       " \" LETS'S HOPE THE TRIP TO BE GREAT\"]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2.split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a8faab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent3 = \"AMERICA IS VERY BEAUTIFULL COUNTRY. IT IS MOST POWERFULL COUNTRY IN THE WORLD. NEW YORK CITY IS THE MOST BEAUTIFULL AND EXPENSIVE CITY TO LIVE IN THE WHOLE WORLD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "cffc6f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AMERICA IS VERY BEAUTIFULL COUNTRY',\n",
       " ' IT IS MOST POWERFULL COUNTRY IN THE WORLD',\n",
       " ' NEW YORK CITY IS THE MOST BEAUTIFULL AND EXPENSIVE CITY TO LIVE IN THE WHOLE WORLD']"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent3.split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "bdd8dd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROBLEMS WITH SPLIT FUNCTION\n",
    "sent4= \"I AM GOING TO USA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "79bf7ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'AM', 'GOING', 'TO', 'USA']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent4.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "19d97cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent5= \"WHICH CITY DO YOU THINK SHOULD I VISIT IN USA?, I HAVE 3 DAYS HOLIDAY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a7e820b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WHICH CITY DO YOU THINK SHOULD I VISIT IN USA?, I HAVE 3 DAYS HOLIDAY']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent5.split(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c361eec0",
   "metadata": {},
   "source": [
    "- REGULAR EXPRESSION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "76850db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = \"I AM GOING TO USA FOR JOB AND MASTER'S!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "61ce62e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = re.findall(r'[\\w]+', S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2a041cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'AM', 'GOING', 'TO', 'USA', 'FOR', 'JOB', 'AND', 'MASTER', 'S']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ca4299dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \" I AM GOING INDIA FOR SUMMER HOLYDAYS!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c24a83fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = re.findall(r'[\\w+]+', s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "278a2726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'AM', 'GOING', 'INDIA', 'FOR', 'SUMMER', 'HOLYDAYS']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29b3ec7",
   "metadata": {},
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2fcaf044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "32b77ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "U = \"I AM GOING TO VISIT LAS VEGAS TO SEE MY COUSIN BROTHER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "30f565b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'AM',\n",
       " 'GOING',\n",
       " 'TO',\n",
       " 'VISIT',\n",
       " 'LAS',\n",
       " 'VEGAS',\n",
       " 'TO',\n",
       " 'SEE',\n",
       " 'MY',\n",
       " 'COUSIN',\n",
       " 'BROTHER']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "42667c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "U1 = \"I AM GOING TO WHITNEY POINT TO SEE MY FRIEND NIKHIL AND GONNA STAY AT HIS HOUSE TILL NIGHT \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7a7af8e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'AM',\n",
       " 'GOING',\n",
       " 'TO',\n",
       " 'WHITNEY',\n",
       " 'POINT',\n",
       " 'TO',\n",
       " 'SEE',\n",
       " 'MY',\n",
       " 'FRIEND',\n",
       " 'NIKHIL',\n",
       " 'AND',\n",
       " 'GON',\n",
       " 'NA',\n",
       " 'STAY',\n",
       " 'AT',\n",
       " 'HIS',\n",
       " 'HOUSE',\n",
       " 'TILL',\n",
       " 'NIGHT']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(U1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ee024348",
   "metadata": {},
   "outputs": [],
   "source": [
    "U2 = \"I WANT TO VISIT CHANDRAPUR TO MEET MY MOM AND A 220 KM RIDE COSTS $10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "259dec34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'WANT',\n",
       " 'TO',\n",
       " 'VISIT',\n",
       " 'CHANDRAPUR',\n",
       " 'TO',\n",
       " 'MEET',\n",
       " 'MY',\n",
       " 'MOM',\n",
       " 'AND',\n",
       " 'A',\n",
       " '220',\n",
       " 'KM',\n",
       " 'RIDE',\n",
       " 'COSTS',\n",
       " '$',\n",
       " '10']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(U2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6833383d",
   "metadata": {},
   "source": [
    "## STEMMING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bcf09a",
   "metadata": {},
   "source": [
    "- \"the process of reducing a word to its word stem that affixes to suffixes and prefixes or the roots\"\n",
    " \n",
    "- Stemming is a technique used to reduce an inflected word down to its word stem. For example, the words “programming,” “programmer,” and “programs” can all be reduced down to the common word stem “program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "733e2f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "1499b15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "9698621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#or "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "60932edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "73f25aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'program'"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"programming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "5578e818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'playing or danc'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"playing or dancing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "cbd3eff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(text):\n",
    "    new_text= []\n",
    "    for w in text.split():\n",
    "        new_text.append(stemmer.stem())\n",
    "   \n",
    "    return \" \".join(new_text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c754c2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'program'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"programming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "39a60a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk'"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"walked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "5529915a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_word(text):\n",
    "    New_text = []\n",
    "    for u in text.split():\n",
    "        New_text.append(stemmer.stem())\n",
    "    return \" \".join(New_text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "3da433ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdata[\"docs\"]= dfdata[\"docs\"].apply(stemmer.stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "f40ae6bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"betty botter bought some butter but she said the butter's bitter if i put it in my batter, it will make my batter bitter but a bit of better butter will make my batter better so 'twas better betty botter bought a bit of better butt\""
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdata[\"docs\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "3c81d7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "e768360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return \" \".join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "3dba9320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_words(text):\n",
    "    return \" \".join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "ba5c782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"walks walked walking\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "b9a59d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk walk walk'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_words(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "fc90c8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "UK = \"I LIKE TO PLAY CRICKET AND LIKE TO DRAW SKETCHES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "219ba63c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i like to play cricket and like to draw sketch'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_words(UK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "7268f974",
   "metadata": {},
   "outputs": [],
   "source": [
    "UTK = \"What is forecasting in Python, the Time series forecasting is a method in the statistics field to analyze historical data with a time component and create a prediction based on it. Some classic examples of time series forecasting methods are Moving Average, ARIMA, and Exponential Smoothing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "93b23105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what is forecast in python, the time seri forecast is a method in the statist field to analyz histor data with a time compon and creat a predict base on it. some classic exampl of time seri forecast method are move average, arima, and exponenti smooth'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_words(UTK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1af1b83",
   "metadata": {},
   "source": [
    "## LEMMATIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7e89ba",
   "metadata": {},
   "source": [
    "- \"Lemmatization is a text pre-processing technique used in natural language processing (NLP) models to break a word down to its root meaning to identify similarities.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adcd4fa",
   "metadata": {},
   "source": [
    "- NLTK (Natural Language Toolkit) is a Python library used for natural language processing. One of its modules is the WordNet Lemmatizer, which can be used to perform lemmatization on words.\n",
    "\n",
    "- Lemmatization is the process of reducing a word to its base or dictionary form, known as the lemma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "608c5625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    " \n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "95834825",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"He was running and eating at a same time. He has bad habit of swimming after eating and plaing long hours in the sun.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9b598a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943462c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a11eb4db",
   "metadata": {},
   "source": [
    "# TEXT VECTORIZATION OR TEXT REPRESENTATION OR FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e010735",
   "metadata": {},
   "source": [
    "- \" Vectorization or word embedding is the process of converting text data to numerical vectors\".\n",
    "- Word Embeddings or Word vectorization is a methodology in NLP to map words or phrases from vocabulary to a corresponding vector of real numbers which used to find word predictions, word similarities/semanticsmm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259d67a0",
   "metadata": {},
   "source": [
    "- CORPUS :\n",
    "- what is meant by corpus : the cobination of all words in a dataset is called as corpus,\n",
    "- A corpus is a collection of documents\n",
    "- A corpus is a collection of authentic text or audio organized into datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6727ff32",
   "metadata": {},
   "source": [
    "- VOCABULARY :\n",
    "- The set of unique words used in the text corpus is referred to as the vocabulary.\n",
    "- A corpus is made up of all the unique words. and If you remove all the unique words from a corpus, you will have a vocabulary or it will be a vocabulary.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187d11a5",
   "metadata": {},
   "source": [
    "- DOCUMENTS:  If we have 100 sentences, each sentence is a document. Mathematical Representation of Documents is Vector.\n",
    "- \n",
    "\n",
    "\n",
    "- What is the difference between a document and a corpus in NLP?: \n",
    "- Corpus is a collection of Documents. It is a unique text different from the corpus. If we have 100 sentences, each sentence is a document. Mathematical Representation of Documents is Vecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "97f2eeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "54a2455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "1fdec0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOW =cv.fit_transform(dfdata[\"docs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "86c2883a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'betty': 5,\n",
       " 'botter': 8,\n",
       " 'bought': 9,\n",
       " 'some': 40,\n",
       " 'butter': 12,\n",
       " 'but': 10,\n",
       " 'she': 34,\n",
       " 'said': 32,\n",
       " 'the': 42,\n",
       " 'bitter': 7,\n",
       " 'if': 19,\n",
       " 'put': 30,\n",
       " 'it': 21,\n",
       " 'in': 20,\n",
       " 'my': 26,\n",
       " 'batter': 2,\n",
       " 'will': 47,\n",
       " 'make': 25,\n",
       " 'bit': 6,\n",
       " 'of': 29,\n",
       " 'better': 4,\n",
       " 'so': 39,\n",
       " 'twas': 44,\n",
       " 'butt': 11,\n",
       " 'susie': 41,\n",
       " 'works': 48,\n",
       " 'shoeshine': 36,\n",
       " 'shop': 37,\n",
       " 'where': 46,\n",
       " 'shines': 35,\n",
       " 'sits': 38,\n",
       " 'and': 0,\n",
       " 'have': 18,\n",
       " 'got': 17,\n",
       " 'date': 13,\n",
       " 'at': 1,\n",
       " 'quarter': 31,\n",
       " 'to': 43,\n",
       " 'eight': 15,\n",
       " 'll': 24,\n",
       " 'see': 33,\n",
       " 'you': 50,\n",
       " 'gate': 16,\n",
       " 'don': 14,\n",
       " 'be': 3,\n",
       " 'late': 23,\n",
       " 'know': 22,\n",
       " 'new': 28,\n",
       " 'york': 49,\n",
       " 'need': 27,\n",
       " 'unique': 45}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#VOCABULARY\n",
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "8e360b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 2, 1, 1, 2, 0, 0, 1, 0, 0,\n",
       "        0, 0, 2, 0, 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOW[1].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "f081ffb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "        0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOW[2].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "e0c6aa34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        2, 0, 0, 0, 0, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 3, 4]], dtype=int64)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOW[3].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "54e9d48e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 3, 0, 4, 2, 2, 2, 2, 2, 2, 1, 3, 0, 0, 0, 0, 0, 0, 1, 1, 2,\n",
       "        0, 0, 0, 2, 3, 0, 0, 2, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "        1, 0, 0, 2, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOW[0].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d7e1f8",
   "metadata": {},
   "source": [
    "- BAG OF WORDS : \"Bag of words is a Natural Language Processing technique of text modelling. In technical terms, we can say that it is a method of feature extraction with text data. This approach is a simple and flexible way of extracting features from documents.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae3e478",
   "metadata": {},
   "source": [
    "- BI-GRAM : \"A bigram language model is a type of statistical language model that predicts the probability of a word in a sequence based on the previous word.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b543ece0",
   "metadata": {},
   "source": [
    "- N-GRAM : \"N-grams are defined as the contiguous sequence of n items that can be extracted from a given sample of text or speech. The items can be letters, words, or base pairs, according to the application. The N-grams typically are collected from a text or speech corpus\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4db893",
   "metadata": {},
   "source": [
    "- UNI-GRAMS: \" A 1-gram (unigram) is a single word sequence of words like “please” or “ turn”. – A 2-gram (bigram) is a two-word sequence of words like “please turn”, “turn your”, or ”your homework”. – A 3-gram (trigram) is a three-word sequence of words like “please turn your”, or “turn your homework”.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "aef28b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "utk = pd.DataFrame({\"text\": [\"I AM READY TO GO TO AMERICA\", \"THE PLANE IS READY TO TAKE OFF\", \"THE PLANE IS ABOUT TO LAND AT THE NEW YORK AIRPORT IN JUST A FEW MINUTES \"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "5edcb5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I AM READY TO GO TO AMERICA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THE PLANE IS READY TO TAKE OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>THE PLANE IS ABOUT TO LAND AT THE NEW YORK AIR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                        I AM READY TO GO TO AMERICA\n",
       "1                     THE PLANE IS READY TO TAKE OFF\n",
       "2  THE PLANE IS ABOUT TO LAND AT THE NEW YORK AIR..."
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "80c24368",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "04062641",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram = cv.fit_transform(utk[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "54261b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x20 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 26 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "3bbad281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0],\n",
       "       [1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 2, 1, 1]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "64f5f6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'am': 2,\n",
       " 'ready': 15,\n",
       " 'to': 18,\n",
       " 'go': 6,\n",
       " 'america': 3,\n",
       " 'the': 17,\n",
       " 'plane': 14,\n",
       " 'is': 8,\n",
       " 'take': 16,\n",
       " 'off': 13,\n",
       " 'about': 0,\n",
       " 'land': 10,\n",
       " 'at': 4,\n",
       " 'new': 12,\n",
       " 'york': 19,\n",
       " 'airport': 1,\n",
       " 'in': 7,\n",
       " 'just': 9,\n",
       " 'few': 5,\n",
       " 'minutes': 11}"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "7fbdf487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t1\n",
      "  (0, 15)\t1\n",
      "  (0, 18)\t2\n",
      "  (0, 6)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 15)\t1\n",
      "  (1, 18)\t1\n",
      "  (1, 17)\t1\n",
      "  (1, 14)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 16)\t1\n",
      "  (1, 13)\t1\n",
      "  (2, 18)\t1\n",
      "  (2, 17)\t2\n",
      "  (2, 14)\t1\n",
      "  (2, 8)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 10)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 12)\t1\n",
      "  (2, 19)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 7)\t1\n",
      "  (2, 9)\t1\n",
      "  (2, 5)\t1\n",
      "  (2, 11)\t1\n"
     ]
    }
   ],
   "source": [
    "print(unigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "d1f65342",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "aeda011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram=cv.fit_transform(utk[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "3ad0cfa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x22 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 25 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "c7cd58f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0],\n",
       "       [1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "f89e24f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'am ready': 2,\n",
       " 'ready to': 13,\n",
       " 'to go': 18,\n",
       " 'go to': 5,\n",
       " 'to america': 17,\n",
       " 'the plane': 16,\n",
       " 'plane is': 12,\n",
       " 'is ready': 8,\n",
       " 'to take': 20,\n",
       " 'take off': 14,\n",
       " 'is about': 7,\n",
       " 'about to': 0,\n",
       " 'to land': 19,\n",
       " 'land at': 10,\n",
       " 'at the': 3,\n",
       " 'the new': 15,\n",
       " 'new york': 11,\n",
       " 'york airport': 21,\n",
       " 'airport in': 1,\n",
       " 'in just': 6,\n",
       " 'just few': 9,\n",
       " 'few minutes': 4}"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "359a5082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 18)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 17)\t1\n",
      "  (1, 13)\t1\n",
      "  (1, 16)\t1\n",
      "  (1, 12)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 20)\t1\n",
      "  (1, 14)\t1\n",
      "  (2, 16)\t1\n",
      "  (2, 12)\t1\n",
      "  (2, 7)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 19)\t1\n",
      "  (2, 10)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 15)\t1\n",
      "  (2, 11)\t1\n",
      "  (2, 21)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 6)\t1\n",
      "  (2, 9)\t1\n",
      "  (2, 4)\t1\n"
     ]
    }
   ],
   "source": [
    "print(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "e3f326a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "e6a19565",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram= cv.fit_transform(utk[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "335bd44b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x21 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 22 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "955aa007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0],\n",
       "       [1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "8bbb37d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'am ready to': 2,\n",
       " 'ready to go': 13,\n",
       " 'to go to': 17,\n",
       " 'go to america': 4,\n",
       " 'the plane is': 16,\n",
       " 'plane is ready': 12,\n",
       " 'is ready to': 7,\n",
       " 'ready to take': 14,\n",
       " 'to take off': 19,\n",
       " 'plane is about': 11,\n",
       " 'is about to': 6,\n",
       " 'about to land': 0,\n",
       " 'to land at': 18,\n",
       " 'land at the': 9,\n",
       " 'at the new': 3,\n",
       " 'the new york': 15,\n",
       " 'new york airport': 10,\n",
       " 'york airport in': 20,\n",
       " 'airport in just': 1,\n",
       " 'in just few': 5,\n",
       " 'just few minutes': 8}"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "32480459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 17)\t1\n",
      "  (0, 4)\t1\n",
      "  (1, 16)\t1\n",
      "  (1, 12)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 14)\t1\n",
      "  (1, 19)\t1\n",
      "  (2, 16)\t1\n",
      "  (2, 11)\t1\n",
      "  (2, 6)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 18)\t1\n",
      "  (2, 9)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 15)\t1\n",
      "  (2, 10)\t1\n",
      "  (2, 20)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 5)\t1\n",
      "  (2, 8)\t1\n"
     ]
    }
   ],
   "source": [
    "print(trigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c568ea6",
   "metadata": {},
   "source": [
    "## TF-IDF VECTORIZER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6062c3b",
   "metadata": {},
   "source": [
    "- \"TF-IDF is technique in Natural Language Processing for converting words in Vectors and with some semantic information and it gives weighted to uncommon words\"\n",
    "- \"TF-IDF is useful in many natural language processing applications. For example, Search Engines use TF-IDF to rank the relevance of a document for a query. TF-IDF is also employed in text classification, text summarization, and topic modeling.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031e84ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "e1bf8bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "8de05a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "5e88c4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I AM READY TO GO TO AMERICA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THE PLANE IS READY TO TAKE OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>THE PLANE IS ABOUT TO LAND AT THE NEW YORK AIR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                        I AM READY TO GO TO AMERICA\n",
       "1                     THE PLANE IS READY TO TAKE OFF\n",
       "2  THE PLANE IS ABOUT TO LAND AT THE NEW YORK AIR..."
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "4857fb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.44839402, 0.44839402, 0.        ,\n",
       "        0.        , 0.44839402, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.34101521, 0.        , 0.        , 0.52965746, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.35221512, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.46312056, 0.35221512,\n",
       "        0.35221512, 0.46312056, 0.35221512, 0.27352646, 0.        ],\n",
       "       [0.26900365, 0.26900365, 0.        , 0.        , 0.26900365,\n",
       "        0.26900365, 0.        , 0.26900365, 0.20458421, 0.26900365,\n",
       "        0.26900365, 0.26900365, 0.26900365, 0.        , 0.20458421,\n",
       "        0.        , 0.        , 0.40916842, 0.15887789, 0.26900365]])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfvectorizer.fit_transform(utk[\"text\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "0f97e4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.69314718 1.69314718 1.69314718 1.69314718 1.69314718 1.69314718\n",
      " 1.69314718 1.69314718 1.28768207 1.69314718 1.69314718 1.69314718\n",
      " 1.69314718 1.69314718 1.28768207 1.28768207 1.69314718 1.28768207\n",
      " 1.         1.69314718]\n"
     ]
    }
   ],
   "source": [
    "print(tfidfvectorizer.idf_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "6b49915a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfidfvectorizer_feature_names_out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[237], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(tfidfvectorizer_feature_names_out())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tfidfvectorizer_feature_names_out' is not defined"
     ]
    }
   ],
   "source": [
    "print(tfidfvectorizer_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfcf799",
   "metadata": {},
   "source": [
    "## DEEP LEARNING APPROACHES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a194ae98",
   "metadata": {},
   "source": [
    "- \"Deep learning is a machine learning technique that teaches computers to do what comes naturally to humans: learn by example. Deep learning is a key technology behind driverless cars, enabling them to recognize a stop sign, or to distinguish a pedestrian from a lamppost.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613f3dc2",
   "metadata": {},
   "source": [
    "# WORD2VEC "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e402f6d8",
   "metadata": {},
   "source": [
    "- Word2Vec can capture symantic meaning like ex:- Happy and Joy it can recognise that i have same meaning\n",
    "- Low have dimension so computational can be fast \n",
    "- Dense Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0174321d",
   "metadata": {},
   "source": [
    "- CBOW:- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "e988c0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "14a01049",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrd2vecembedding = Word2Vec(list(utk[\"text\"].str.split()), vector_size = 10, min_count= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "0ab401ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x1f451491510>"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrd2vecembedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "1b5a14d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.word2vec.Word2Vec"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(wrd2vecembedding )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "e684557d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_adapt_by_suffix', '_check_corpus_sanity', '_check_training_sanity', '_clear_post_train', '_do_train_epoch', '_do_train_job', '_get_next_alpha', '_get_thread_working_mem', '_job_producer', '_load_specials', '_log_epoch_end', '_log_epoch_progress', '_log_progress', '_log_train_end', '_raw_word_count', '_save_specials', '_scan_vocab', '_smart_save', '_train_epoch', '_train_epoch_corpusfile', '_worker_loop', '_worker_loop_corpusfile', 'add_lifecycle_event', 'add_null_word', 'alpha', 'batch_words', 'build_vocab', 'build_vocab_from_freq', 'cbow_mean', 'comment', 'compute_loss', 'corpus_count', 'corpus_total_words', 'create_binary_tree', 'cum_table', 'effective_min_count', 'epochs', 'estimate_memory', 'get_latest_training_loss', 'hashfxn', 'hs', 'init_sims', 'init_weights', 'layer1_size', 'lifecycle_events', 'load', 'make_cum_table', 'max_final_vocab', 'max_vocab_size', 'min_alpha', 'min_alpha_yet_reached', 'min_count', 'negative', 'ns_exponent', 'null_word', 'predict_output_word', 'prepare_vocab', 'prepare_weights', 'random', 'raw_vocab', 'reset_from', 'running_training_loss', 'sample', 'save', 'scan_vocab', 'score', 'seed', 'seeded_vector', 'sg', 'shrink_windows', 'sorted_vocab', 'syn1neg', 'total_train_time', 'train', 'train_count', 'update_weights', 'vector_size', 'window', 'workers', 'wv']\n"
     ]
    }
   ],
   "source": [
    "print(dir(wrd2vecembedding ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "c079c004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__contains__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_adapt_by_suffix', '_load_specials', '_log_evaluate_word_analogies', '_save_specials', '_smart_save', '_upconvert_old_d2vkv', '_upconvert_old_vocab', 'add_lifecycle_event', 'add_vector', 'add_vectors', 'allocate_vecattrs', 'closer_than', 'cosine_similarities', 'distance', 'distances', 'doesnt_match', 'evaluate_word_analogies', 'evaluate_word_pairs', 'expandos', 'fill_norms', 'get_index', 'get_mean_vector', 'get_normed_vectors', 'get_vecattr', 'get_vector', 'has_index_for', 'index2entity', 'index2word', 'index_to_key', 'init_sims', 'intersect_word2vec_format', 'key_to_index', 'load', 'load_word2vec_format', 'log_accuracy', 'log_evaluate_word_pairs', 'mapfile_path', 'most_similar', 'most_similar_cosmul', 'most_similar_to_given', 'n_similarity', 'next_index', 'norms', 'rank', 'rank_by_centrality', 'relative_cosine_similarity', 'resize_vectors', 'save', 'save_word2vec_format', 'set_vecattr', 'similar_by_key', 'similar_by_vector', 'similar_by_word', 'similarity', 'similarity_unseen_docs', 'sort_by_descending_frequency', 'unit_normalize_all', 'vector_size', 'vectors', 'vectors_for_all', 'vectors_lockf', 'vectors_norm', 'vocab', 'wmdistance', 'word_vec', 'words_closer_than']\n"
     ]
    }
   ],
   "source": [
    "print(dir(wrd2vecembedding.wv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "388c932c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00539552,  0.00232393,  0.05100326,  0.0899847 , -0.09300875,\n",
       "        -0.07111891,  0.06463242,  0.08981007, -0.05018915, -0.03759257],\n",
       "       [ 0.07381411, -0.01535229, -0.04539502,  0.06555288, -0.04860752,\n",
       "        -0.01814488,  0.0287871 ,  0.00994161, -0.08287872, -0.0945075 ],\n",
       "       [ 0.07311766,  0.05070262,  0.06757693,  0.00762866,  0.06350891,\n",
       "        -0.03405366, -0.00946401,  0.05768573, -0.07521638, -0.03936104],\n",
       "       [-0.07511376, -0.00934256,  0.09540984, -0.07337879, -0.02327469,\n",
       "        -0.01933269,  0.08083545, -0.05925278,  0.00047569, -0.04742986],\n",
       "       [-0.09604025,  0.05006899, -0.08761217, -0.0439361 , -0.0003551 ,\n",
       "        -0.00295094, -0.07660891,  0.09616972,  0.04980387,  0.09233835],\n",
       "       [-0.08155638,  0.04493742, -0.04138051,  0.00817817,  0.08500696,\n",
       "        -0.04459886,  0.04518904, -0.06782202, -0.03547909,  0.09402988],\n",
       "       [-0.01577862,  0.00308955, -0.04150177, -0.07691965, -0.01502094,\n",
       "         0.02482391, -0.00877448,  0.05550457, -0.02750579,  0.02263772],\n",
       "       [ 0.05455794,  0.08345953, -0.01453741, -0.09208143,  0.04370552,\n",
       "         0.00571785,  0.07441908, -0.00813283, -0.02638414, -0.08753009],\n",
       "       [-0.00857016,  0.02826096,  0.0540292 ,  0.07050257, -0.05702755,\n",
       "         0.01859065,  0.06090363, -0.04798361, -0.03105995,  0.06798041],\n",
       "       [ 0.01631632,  0.00189816,  0.03473707,  0.00218488,  0.09618811,\n",
       "         0.05060505, -0.0891696 , -0.07041812,  0.00901375,  0.06392585],\n",
       "       [-0.08619688,  0.03665738,  0.05189884,  0.05741938,  0.07466918,\n",
       "        -0.06167675,  0.01105614,  0.06047282, -0.0284005 , -0.06173522],\n",
       "       [-0.00411764, -0.08368589, -0.05598853,  0.07104015,  0.03352253,\n",
       "         0.07225412,  0.06801618,  0.07529087, -0.03789892, -0.00562238],\n",
       "       [ 0.02350009, -0.04529419,  0.08384062, -0.09869492,  0.0676968 ,\n",
       "         0.02924688, -0.04921033,  0.04412061, -0.01740559,  0.06719152],\n",
       "       [ 0.0996748 , -0.04366238, -0.00601846, -0.05696345,  0.03852775,\n",
       "         0.02790027,  0.06895097,  0.06106038,  0.09539854,  0.09276399],\n",
       "       [ 0.07896214, -0.06992096, -0.09156968, -0.00365155, -0.03097867,\n",
       "         0.07897475,  0.05942691, -0.01540702,  0.01509838,  0.01793992],\n",
       "       [ 0.07817571, -0.09510187, -0.00205531,  0.03469197, -0.00938972,\n",
       "         0.08381772,  0.09010784,  0.06536506, -0.00711621,  0.07710405],\n",
       "       [-0.08538009,  0.03208666, -0.04636488, -0.05090275,  0.0358959 ,\n",
       "         0.05369444,  0.07768843, -0.05770025,  0.07433287,  0.06623191],\n",
       "       [-0.037098  , -0.08745642,  0.05437467,  0.06509756, -0.0078755 ,\n",
       "        -0.06709856, -0.07085925, -0.0249706 ,  0.05143254, -0.03665238],\n",
       "       [-0.09364896,  0.03822529,  0.04884146, -0.06432878,  0.01211125,\n",
       "        -0.02071684,  0.00025944, -0.09876948,  0.02691976, -0.04745426],\n",
       "       [ 0.01087646, -0.01576225,  0.02196673, -0.07881576, -0.02717184,\n",
       "         0.02663199,  0.05346682, -0.02391515, -0.09510094,  0.04505879],\n",
       "       [ 0.00094564,  0.0307732 , -0.06812645, -0.01375465,  0.07668581,\n",
       "         0.0734641 , -0.03673297,  0.02642702, -0.08317129,  0.06205486],\n",
       "       [-0.04637323, -0.03164107,  0.09311356,  0.00873386,  0.07490703,\n",
       "        -0.06074063,  0.05160507,  0.09922823, -0.08457391, -0.05135691]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrd2vecembedding.wv.__getitem__(wrd2vecembedding.wv.index_to_key) # every word's vector representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "7a9ac9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wrd2vecembedding.wv.__getitem__(wrd2vecembedding.wv.index_to_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "ecb97d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TO': 0, 'THE': 1, 'READY': 2, 'PLANE': 3, 'IS': 4, 'MINUTES': 5, 'FEW': 6, 'AM': 7, 'GO': 8, 'AMERICA': 9, 'TAKE': 10, 'OFF': 11, 'ABOUT': 12, 'LAND': 13, 'AT': 14, 'NEW': 15, 'YORK': 16, 'AIRPORT': 17, 'IN': 18, 'JUST': 19, 'A': 20, 'I': 21}\n"
     ]
    }
   ],
   "source": [
    "print(wrd2vecembedding.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "d51837bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00539552,  0.00232393,  0.05100326,  0.0899847 , -0.09300875,\n",
       "       -0.07111891,  0.06463242,  0.08981007, -0.05018915, -0.03759257],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrd2vecembedding.wv.__getitem__(wrd2vecembedding.wv.index_to_key)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "3106a249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.07311766,  0.05070262,  0.06757693,  0.00762866,  0.06350891,\n",
       "       -0.03405366, -0.00946401,  0.05768573, -0.07521638, -0.03936104],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrd2vecembedding.wv.__getitem__(wrd2vecembedding.wv.index_to_key)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1276054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "967309e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TO', 'THE', 'READY', 'PLANE', 'IS', 'MINUTES', 'FEW', 'AM', 'GO', 'AMERICA', 'TAKE', 'OFF', 'ABOUT', 'LAND', 'AT', 'NEW', 'YORK', 'AIRPORT', 'IN', 'JUST', 'A', 'I']\n"
     ]
    }
   ],
   "source": [
    "print(wrd2vecembedding.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "6d8c2142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(utk[\"text\"][2].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "04043d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "uk = list(utk[\"text\"][2].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "1c802f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['THE',\n",
       " 'PLANE',\n",
       " 'IS',\n",
       " 'ABOUT',\n",
       " 'TO',\n",
       " 'LAND',\n",
       " 'AT',\n",
       " 'THE',\n",
       " 'NEW',\n",
       " 'YORK',\n",
       " 'AIRPORT',\n",
       " 'IN',\n",
       " 'JUST',\n",
       " 'A',\n",
       " 'FEW',\n",
       " 'MINUTES']"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "4008cad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07381411, -0.01535229, -0.04539502,  0.06555288, -0.04860752,\n",
       "        -0.01814488,  0.0287871 ,  0.00994161, -0.08287872, -0.0945075 ],\n",
       "       [-0.07511376, -0.00934256,  0.09540984, -0.07337879, -0.02327469,\n",
       "        -0.01933269,  0.08083545, -0.05925278,  0.00047569, -0.04742986],\n",
       "       [-0.09604025,  0.05006899, -0.08761217, -0.0439361 , -0.0003551 ,\n",
       "        -0.00295094, -0.07660891,  0.09616972,  0.04980387,  0.09233835],\n",
       "       [ 0.02350009, -0.04529419,  0.08384062, -0.09869492,  0.0676968 ,\n",
       "         0.02924688, -0.04921033,  0.04412061, -0.01740559,  0.06719152],\n",
       "       [-0.00539552,  0.00232393,  0.05100326,  0.0899847 , -0.09300875,\n",
       "        -0.07111891,  0.06463242,  0.08981007, -0.05018915, -0.03759257],\n",
       "       [ 0.0996748 , -0.04366238, -0.00601846, -0.05696345,  0.03852775,\n",
       "         0.02790027,  0.06895097,  0.06106038,  0.09539854,  0.09276399],\n",
       "       [ 0.07896214, -0.06992096, -0.09156968, -0.00365155, -0.03097867,\n",
       "         0.07897475,  0.05942691, -0.01540702,  0.01509838,  0.01793992],\n",
       "       [ 0.07381411, -0.01535229, -0.04539502,  0.06555288, -0.04860752,\n",
       "        -0.01814488,  0.0287871 ,  0.00994161, -0.08287872, -0.0945075 ],\n",
       "       [ 0.07817571, -0.09510187, -0.00205531,  0.03469197, -0.00938972,\n",
       "         0.08381772,  0.09010784,  0.06536506, -0.00711621,  0.07710405],\n",
       "       [-0.08538009,  0.03208666, -0.04636488, -0.05090275,  0.0358959 ,\n",
       "         0.05369444,  0.07768843, -0.05770025,  0.07433287,  0.06623191],\n",
       "       [-0.037098  , -0.08745642,  0.05437467,  0.06509756, -0.0078755 ,\n",
       "        -0.06709856, -0.07085925, -0.0249706 ,  0.05143254, -0.03665238],\n",
       "       [-0.09364896,  0.03822529,  0.04884146, -0.06432878,  0.01211125,\n",
       "        -0.02071684,  0.00025944, -0.09876948,  0.02691976, -0.04745426],\n",
       "       [ 0.01087646, -0.01576225,  0.02196673, -0.07881576, -0.02717184,\n",
       "         0.02663199,  0.05346682, -0.02391515, -0.09510094,  0.04505879],\n",
       "       [ 0.00094564,  0.0307732 , -0.06812645, -0.01375465,  0.07668581,\n",
       "         0.0734641 , -0.03673297,  0.02642702, -0.08317129,  0.06205486],\n",
       "       [-0.01577862,  0.00308955, -0.04150177, -0.07691965, -0.01502094,\n",
       "         0.02482391, -0.00877448,  0.05550457, -0.02750579,  0.02263772],\n",
       "       [-0.08155638,  0.04493742, -0.04138051,  0.00817817,  0.08500696,\n",
       "        -0.04459886,  0.04518904, -0.06782202, -0.03547909,  0.09402988]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrd2vecembedding.wv.__getitem__(uk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "658e84b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00314053, -0.01223376, -0.00749892, -0.01451802,  0.00072714,\n",
       "        0.00852797,  0.0222466 ,  0.00690646, -0.01051649,  0.01745043],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrd2vecembedding.wv.__getitem__(uk).mean(axis= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cdd3bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
